{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe5bacbb",
      "metadata": {
        "id": "fe5bacbb"
      },
      "source": [
        "# Exercise: Implementing Motion Detection Using Background Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3332331",
      "metadata": {
        "id": "a3332331"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17c3591",
      "metadata": {
        "id": "e17c3591"
      },
      "source": [
        "In this exercise, you will implement motion detection in a video using background subtraction. Follow the steps outlined below and write the corresponding code for each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2309fa4f",
      "metadata": {
        "id": "2309fa4f"
      },
      "source": [
        "### Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "vwqPv3M2l8nz"
      },
      "id": "vwqPv3M2l8nz",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9183a82",
      "metadata": {
        "id": "a9183a82"
      },
      "source": [
        "### Step 2: Set Up Video Capture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ada6fe",
      "metadata": {
        "id": "43ada6fe"
      },
      "source": [
        "Initialize the video capture object by loading the video file (e.g., `video.mp4`). This object will allow you to read frames from the video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/Motion_Detection_Test.mp4')"
      ],
      "metadata": {
        "id": "5YTx_g-fl-QY"
      },
      "id": "5YTx_g-fl-QY",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0072f6cf",
      "metadata": {
        "id": "0072f6cf"
      },
      "source": [
        "### Step 3: Define the Video Writer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f32d9d6",
      "metadata": {
        "id": "8f32d9d6"
      },
      "source": [
        "Set up a `VideoWriter` object to save the processed video with motion detection. Choose the appropriate codec (e.g., `'mp4v'`) and specify the frame rate and resolution for the output video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output.mp4', fourcc, 20.0, (600, 500))"
      ],
      "metadata": {
        "id": "exSdbEE5l_ut"
      },
      "id": "exSdbEE5l_ut",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5d81bbd",
      "metadata": {
        "id": "f5d81bbd"
      },
      "source": [
        "### Step 4: Create the Background Subtractor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd55e96",
      "metadata": {
        "id": "ddd55e96"
      },
      "source": [
        "Use OpenCV's MOG2 background subtractor to create a background model that will help detect moving objects. Set `detectShadows=True` to improve detection accuracy by accounting for shadows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)"
      ],
      "metadata": {
        "id": "nr_7PlafmA1H"
      },
      "id": "nr_7PlafmA1H",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "11c3ee89",
      "metadata": {
        "id": "11c3ee89"
      },
      "source": [
        "### Step 5: Process the Video Frame by Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2c952d",
      "metadata": {
        "id": "6e2c952d"
      },
      "source": [
        "1. In a loop, capture each frame from the video.\n",
        "2. Resize the frame for consistency.\n",
        "3. Apply the background subtractor to detect moving objects in the frame.\n",
        "4. Create a binary thresholded image to isolate the moving objects.\n",
        "5. Apply morphological operations like erosion and dilation to reduce noise and strengthen the detected areas.\n",
        "6. Detect contours (boundaries) of the moving objects.\n",
        "7. For each contour, calculate its area and filter out small movements by considering only contours with areas greater than a certain threshold (e.g., 1200).\n",
        "8. Draw rectangles around the detected moving objects and annotate the motion."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 180, 255, cv2.THRESH_BINARY) # THRESH_BINARY > 0 or 255\n",
        "\n",
        "        # Define a kernel (Filter) for morphological operations\n",
        "        kernel = np.ones((7, 7), np.uint8)\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6) # dilate > quality improve\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # RETR_EXTERNAL > normlize the contour\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour)\n",
        "\n",
        "            # Only consider significant motion (area > 1200)\n",
        "            if area > 1200:\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour) # (x,y) center , (w,h) width , hight\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "                # Write the processed frame with motion detection to the output video\n",
        "                out.write(img)\n",
        "\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Iyae2b1lmBlS"
      },
      "id": "Iyae2b1lmBlS",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "260f89b2",
      "metadata": {
        "id": "260f89b2"
      },
      "source": [
        "### Step 6: Release Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a70401",
      "metadata": {
        "id": "64a70401"
      },
      "source": [
        "After processing all the frames, release the video capture and writer objects to free up system resources. Close any OpenCV windows that were opened during the process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "cnuY8pmNmM_6"
      },
      "id": "cnuY8pmNmM_6",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "66aae989",
      "metadata": {
        "id": "66aae989"
      },
      "source": [
        "### Bonus Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579a8ce5",
      "metadata": {
        "id": "579a8ce5"
      },
      "source": [
        "Try experimenting with different threshold values, kernel sizes, or codecs to optimize the motion detection and improve the output video quality."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the code from the first with diffrent name for output video"
      ],
      "metadata": {
        "id": "safNnenOPYQ5"
      },
      "id": "safNnenOPYQ5"
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/Motion_Detection_Test.mp4')"
      ],
      "metadata": {
        "id": "mjzBh8TPQVQA"
      },
      "id": "mjzBh8TPQVQA",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_bouns_output.mp4', fourcc, 20.0, (600, 500))"
      ],
      "metadata": {
        "id": "5zqFqyjjQE8x"
      },
      "id": "5zqFqyjjQE8x",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)"
      ],
      "metadata": {
        "id": "rVhmoVFKQRC1"
      },
      "id": "rVhmoVFKQRC1",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # Capture each frame of the video\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame is captured successfully\n",
        "    if success:\n",
        "        # Resize the frame for consistency\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        # Apply the background subtractor to detect moving objects\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        # Create a binary thresholded image for better motion detection\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 200, 255, cv2.THRESH_BINARY) # Adjusted threshold value\n",
        "\n",
        "        # Define a kernel (Filter) for morphological operations\n",
        "        kernel = np.ones((5, 5), np.uint8)  # Adjusted kernel size\n",
        "\n",
        "        # Apply erosion to remove noise from the thresholded image\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        # Apply dilation to strengthen the detected moving objects\n",
        "        thresh = cv2.dilate(thresh, None, iterations=4)  # Adjusted number of iterations\n",
        "\n",
        "        # Find contours of the detected motion\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Draw rectangles around detected motion\n",
        "        for contour in contours:\n",
        "            # Calculate the area of the contour\n",
        "            area = cv2.contourArea(contour)\n",
        "\n",
        "            # Only consider significant motion (area > 800)\n",
        "            if area > 800:  # Adjusted area threshold\n",
        "                # Get the bounding box coordinates for the motion\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                # Draw a rectangle around the detected motion and label it\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 2)  # Adjusted line thickness\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)  # Adjusted font size\n",
        "\n",
        "                # Write the processed frame with motion detection to the output video\n",
        "                out.write(img)\n",
        "\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "YvrLkd37J9DI"
      },
      "id": "YvrLkd37J9DI",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UTnRUWpCQMRL"
      },
      "id": "UTnRUWpCQMRL",
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}