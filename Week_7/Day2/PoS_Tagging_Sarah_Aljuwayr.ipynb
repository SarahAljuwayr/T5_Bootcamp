{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "y1xXL2jdBdff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "_IZay8W4Bgp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "hadBfzxIeebQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary resources\n"
      ],
      "metadata": {
        "id": "C8dvIUnhBhjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "ZUzaKoa_BjEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hudvf3j0el2l",
        "outputId": "13d2bbac-ebf6-41a5-be13-03d6b2ea214a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "EWP_F1sYBkEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "OkTzhGvsBldA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\""
      ],
      "metadata": {
        "id": "T0faVsZEexZS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Tokenize the sentence\n",
        "# Tokenization is the process of breaking down the text into individual words or tokens."
      ],
      "metadata": {
        "id": "dJA1CBrMBl5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "id": "lz4mtx9oBq2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLbxrgp8e2zE",
        "outputId": "40ee4bcf-bb7f-4a67-95fe-166d346c8d2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Perform Part of Speech (PoS) tagging\n",
        "# PoS tagging assigns a part of speech to each word (e.g., noun, verb, adjective)."
      ],
      "metadata": {
        "id": "zVaGjcGwBsuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "id": "i7SZQIfEBuQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noo4YlpsfBtl",
        "outputId": "69f417c8-a3f4-4b34-9b3e-b35c64e0252e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "The output of pos_tag is a list of tuples, where each tuple contains a word and its corresponding PoS tag.\n",
        "Common PoS tags include:\n",
        " - NN: Noun\n",
        " - VB: Verb\n",
        " - JJ: Adjective\n",
        " - RB: Adverb\n",
        " - IN: Preposition"
      ],
      "metadata": {
        "id": "jgToAf0GByEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract specific parts of speech\n",
        " Let's extract all nouns (NN) from the tagged words."
      ],
      "metadata": {
        "id": "FG1YwXy7B8de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "id": "zzxtRMP1B94s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkJ_Mi-VgGBp",
        "outputId": "628b8a09-0082-4e0b-a684-cc7c723c5552"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Count the occurrences of each PoS tag\n",
        "We can use a Counter to count how many times each PoS tag appears in the sentence."
      ],
      "metadata": {
        "id": "zwoKuYF2CAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"\\nPoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "NTvpb5MxCCz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])"
      ],
      "metadata": {
        "id": "ZH0QLVZOgUeB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Extract all verbs from the sentence\n",
        "Verbs can have different tags like VB, VBD (past tense), VBG (gerund), etc."
      ],
      "metadata": {
        "id": "W__OyoOXCEsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke_HUhQLAc_W"
      },
      "outputs": [],
      "source": [
        "verbs = [word for word, pos in tagged_words if pos.startswith('VB')]\n",
        "print(\"\\nVerbs:\", verbs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verbs = [word for word, pos in tagged_words if pos.startswith('VB')]\n",
        "print(\"\\nVerbs:\", verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3PeQd5agkzS",
        "outputId": "b50e214d-0b84-4df4-9234-c20686b7e651"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verbs: ['jumps']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "nJ_k6hE8CZr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "J34LLTqACaFS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "0UGjpQb9CbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "-PxjEVcnCdWA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "Z5QsOidjCeRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))"
      ],
      "metadata": {
        "id": "_MUmEuzHCfZI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Extract only the nouns (NN) from the tagged words\n"
      ],
      "metadata": {
        "id": "xeS1f0hnCiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"Nouns:\", nouns)"
      ],
      "metadata": {
        "id": "Jo29Q_XNCVw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48809e1a-d35a-41af-b26b-4ddf95a04008"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "m7-jj2BLClGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QrutpKbmCmZk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence"
      ],
      "metadata": {
        "id": "Y814v2cECm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "bAotCj-TCqCb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "KMGD0NHSCsSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))\n"
      ],
      "metadata": {
        "id": "KnffHvfxCtRt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Count the occurrences of each PoS tag"
      ],
      "metadata": {
        "id": "fnVaIBJcCyhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"PoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "JuTLsdYiCWS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8633a3-80fd-4f97-90c7-fa91167e06e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    }
  ]
}